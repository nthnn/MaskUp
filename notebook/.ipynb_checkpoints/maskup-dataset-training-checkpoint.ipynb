{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d475da26",
   "metadata": {},
   "source": [
    "# Face Mask Detection Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71dd315",
   "metadata": {},
   "source": [
    "Importing important libraries. Proceed if you have the following modules installed already, otherwise:\n",
    "\n",
    "```batch\n",
    "py -m pip install numpy opencv-python keras sklearn tensorflow imutils\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a7dece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import h5py\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense,Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861b0480",
   "metadata": {},
   "source": [
    "This convolutional network utilizes a combination of two Convolutional and MaxPooling layers to extract features from the dataset. Subsequently, a Flatten layer is employed to convert the data into a one-dimensional format, followed by a Dropout layer to mitigate overfitting.\n",
    "\n",
    "Finally, the network incorporates two Dense layers for classification purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5342771",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(100, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Conv2D(100, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4e94e0",
   "metadata": {},
   "source": [
    "The generation and augmentation of the image data for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0e66964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1315 images belonging to 2 classes.\n",
      "Found 194 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('../dataset/train', batch_size=10, target_size=(150, 150))\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "validation_generator = validation_datagen.flow_from_directory('../dataset/test', batch_size=10, target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58520e3",
   "metadata": {},
   "source": [
    "Initialize a callback checkpoint that saves the best model after each epoch during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccce7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('../models/epoch/model-{epoch:03d}.model',\n",
    "                             monitor='val_loss',\n",
    "                             verbose=0,\n",
    "                             save_best_only=True,\n",
    "                             mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f1e1c2",
   "metadata": {},
   "source": [
    "Actual model training and fit generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27583aef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_9360\\3620006576.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - ETA: 0s - loss: 0.6609 - acc: 0.6342INFO:tensorflow:Assets written to: ../models\\model-001.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models\\model-001.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 67s 498ms/step - loss: 0.6609 - acc: 0.6342 - val_loss: 0.4770 - val_acc: 0.9536\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.3769 - acc: 0.8487INFO:tensorflow:Assets written to: ../models\\model-002.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models\\model-002.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 63s 479ms/step - loss: 0.3769 - acc: 0.8487 - val_loss: 0.1058 - val_acc: 0.9588\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.2688 - acc: 0.8913INFO:tensorflow:Assets written to: ../models\\model-003.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models\\model-003.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 64s 483ms/step - loss: 0.2688 - acc: 0.8913 - val_loss: 0.0823 - val_acc: 0.9742\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.2328 - acc: 0.9103INFO:tensorflow:Assets written to: ../models\\model-004.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models\\model-004.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 65s 490ms/step - loss: 0.2328 - acc: 0.9103 - val_loss: 0.0690 - val_acc: 0.9742\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.2225 - acc: 0.9262INFO:tensorflow:Assets written to: ../models\\model-005.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models\\model-005.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 64s 487ms/step - loss: 0.2225 - acc: 0.9262 - val_loss: 0.0580 - val_acc: 0.9691\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 64s 484ms/step - loss: 0.2131 - acc: 0.9202 - val_loss: 0.1542 - val_acc: 0.9381\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 63s 480ms/step - loss: 0.2106 - acc: 0.9209 - val_loss: 0.0588 - val_acc: 0.9794\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 66s 496ms/step - loss: 0.1720 - acc: 0.9361 - val_loss: 0.0887 - val_acc: 0.9639\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 65s 488ms/step - loss: 0.1867 - acc: 0.9392 - val_loss: 0.0900 - val_acc: 0.9639\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 67s 505ms/step - loss: 0.1660 - acc: 0.9384 - val_loss: 0.0776 - val_acc: 0.9639\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              epochs=10,\n",
    "                              validation_data=validation_generator,\n",
    "                              callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec42f0",
   "metadata": {},
   "source": [
    "Now, save the model to a file that will be loaded later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c500dfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natha\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../models/keras_model/maskup-model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa24ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
